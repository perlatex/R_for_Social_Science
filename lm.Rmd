# 线性回归 {#lm}

线性模型是数据分析中最常用的一种分析方法。最基础的往往最深刻。

```{r message = FALSE, warning = FALSE}
library(tidyverse)
```


## 四个前提
线性回归需要满足四个前提假设：

1. **Linearity **
    - 因变量和每个自变量都是线性关系

2. **Indpendence **
    - 对于所有的观测值，它们的误差项相互之间是独立的

3. **Normality **
    - 误差项服从正态分布

4. **Equal-variance **  
    - [所有的误差项具有同样方差](<https://www.zhihu.com/question/67473778>)

这四个假设的首字母，合起来就是\alert{LINE}，这样很好记

## 案例
```{r}
library(rethinking)
data(Howell1)
d <- Howell1
```


```{r}
rm(Howell1)
detach(package:rethinking, unload = T)
library(brms)
```



```{r}
d2 <-
  d %>%
  filter(age >= 18)
```



```{r}
ggplot(
  data = d2,
  aes(x = weight, y = height)
) +
  geom_point(shape = 1, size = 2) +
  theme_bw() +
  theme(panel.grid = element_blank())
```


## 先验概率

```{r}
# prior for mu $\text{Normal}(178, 100)$
p1 <- ggplot(
  data = tibble(x = seq(from = 100, to = 250, by = .1)),
  aes(x = x, y = dnorm(x, mean = 178, sd = 20))
) +
  geom_line() +
  ylab("density")



# prior for beta $\text{Normal}(0, 10)$
p2 <- tibble(beta = -40:40) %>%
  mutate(density = dnorm(beta, mean = 0, sd = 10)) %>%
  ggplot(aes(x = beta, ymin = 0, ymax = density)) +
  geom_ribbon(size = 0, fill = "royalblue") +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(expression(beta)) +
  theme(panel.grid = element_blank())


# prior for sigma $\text{Uniform}(0, 50)$
p3 <- tibble(x = seq(from = -10, to = 60, by = .1)) %>%

  ggplot(aes(x = x, y = dunif(x, min = 0, max = 50))) +
  geom_line() +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

library(patchwork)
p1 + p2 + p3
```

## 模型

```{r}
b4.3 <-
  brm(
    data = d2,
    family = gaussian,
    height ~ 1 + weight,
    prior = c(
      prior(normal(178, 100), class = Intercept),
      prior(normal(0, 10), class = b),
      prior(uniform(0, 50), class = sigma)
    ),
    iter = 41000, warmup = 40000, chains = 4, cores = 4,
    seed = 4,
    file = "fits/b04.03"
  )
```


## 后验概率
```{r}
plot(b4.3)
```


```{r}
summary(b4.3)
```


```{r}
posterior_samples(b4.3) %>% as_tibble()
```

## 预测

### 单个值

```{r}
tb <- tibble(
  weight = 50
)
```

```{r}
post <- tibble(
  pred_height = predict(b4.3, newdata = tb, summary = FALSE)
)
post
```



```{r}
p_cut <- mean(post$pred_height > 150)
p_cut
```


```{r}
library(tidybayes)
# https://cran.r-project.org/web/packages/tidybayes/vignettes/tidybayes.html
post %>%
  ggplot(aes(x = pred_height, y = 0, fill = stat(x > 150))) +
  stat_halfeyeh() +
  geom_vline(
    xintercept = 150, linetype = "dashed", size = 2,
    color = "red"
  ) +
  scale_fill_manual(values = c("gray80", "skyblue")) +
  annotate(
    geom = "label", x = 160, y = 0.25, label = p_cut
  )
```


### 多个值
```{r}
tb <- tibble(
  weight = c(50, 51, 52)
)
```



```{r}
post <-
  predict(b4.3, newdata = tb, summary = FALSE) %>%
  as_tibble() %>%
  set_names(c(50, 51, 52)) %>%
  mutate(iter = 1:n())
post
```


```{r}
prob_cut <- post %>%
  summarise(
    at_50 = mean(`50` > 150),
    at_51 = mean(`51` > 150),
    at_52 = mean(`52` > 150)
  )
prob_cut
```


```{r}
post_longer <- post %>%
  pivot_longer(
    cols = -iter,
    names_to = "weight",
    values_to = "height"
  ) %>%
  mutate(weight = as.numeric(weight))

post_longer
```



```{r}
post_longer %>%
  ggplot(aes(x = height, y = factor(weight), fill = stat(x > 150))) +
  stat_halfeyeh() +
  geom_vline(
    xintercept = 150, linetype = "dashed", size = 2,
    color = "red"
  ) +
  scale_fill_manual(values = c("gray80", "skyblue")) +
  annotate(geom = "label", x = 160, y = 1.4, label = prob_cut$at_50) +
  annotate(geom = "label", x = 160, y = 2.4, label = prob_cut$at_51) +
  annotate(geom = "label", x = 160, y = 3.4, label = prob_cut$at_52)
```
